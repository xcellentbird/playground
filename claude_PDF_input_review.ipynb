{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f9156c5",
   "metadata": {},
   "source": [
    "# Claude - PDF Support\n",
    "- docs: https://platform.claude.com/docs/en/build-with-claude/pdf-support\n",
    "- Claude에서 'PDF Support'을 지원한다.\n",
    "- PDF에서의 텍스트 추출, 차트 분석, 이미지 이해 능력을 갖추고 있다.\n",
    "- use case로, 문서를 다른 정규화된 포맷으로 바꾸는 작업이 소개되어 있다.\n",
    "- PDF input 제한으로, 32MB 크기, 100 pages 제한이 있으며, 패스워드가 걸리지 않아 있어야 한다.\n",
    "- 'PDF support' 기능은 vision capabilities(시각 이해능력)에 의존하기 때문에 claude vision 모델들과 같은 limitation, consideration들을 갖는다.\n",
    "    - 개인적인 의견으로, OCR 형태로 LLM 모델을 사용하는 듯하다. multi language 지원 되는지 확인 필요하며, 글씨체 또한 고려 필요하다. \n",
    "    - claude의 vision limitation, consideration을 살펴보자면,\n",
    "        - vision 작업 API 역시, 이미지 100 per request 제한이 있고, 32MB per request 제한이 있다.\n",
    "        - 성능 최적화를 위해 이미지 한 쪽이 1568 pixel 크기 이상이거나, 1600 토큰 이상이라면, aspect ratio를 유지한 채로 input image resize 작업을 제안한다.\n",
    "        - 이미지 크기가 크면 별다른 성능 향상 없이, TTFT(Time-to-First Token) 지연 시간만 늘어난다.\n",
    "        - 200 pixel 크기 이하의 경우 성능 저하가 있기 때문에 그 이하 낮추지 않도록 한다.\n",
    "        - TTFT를 위해 1.15 Megapixels 크기 이하로 resizing 하는 것을 추천한다.\n",
    "        - 이미지 토큰수 계산은 $tokens = (width \\times height) / 750 $ 와 같이 계산할 수 있다.\n",
    "        - JPEG, PNG, GIF, WebP 포맷을 지원하며\n",
    "        - 인물 식별 작업에 제한 사항이 있으며, 회전되거나 200 pixel 이하의 작은 이미지에 정확도가 낮아지고 hallucination이 있을 수 있다.\n",
    "        - 이미지 내의 정확한 위치나 layout을 인식하는 공간 추론 능력이 부족하다.\n",
    "        - 개체 개수 세는 것이 어렵고, AI 생성 이미지 판별 용도로 사용할 수 없으며, 부적절한 내용에는 요청을 거절하게 되어 있다.\n",
    "    - 한국어 OCR에 대한 내용은 없는 듯하다. 이 부분은 평가 내용 추가하는 것을 고려해야 할 듯하다.\n",
    "- Document Processing Mode로 2 가지가 있는데\n",
    "    - Converse Document Chat: PDF의 텍스트만 추출해서, 그 텍스트 바탕으로 대화를 할 수 있다.\n",
    "    - Claude PDF Chat: PDF 페이지 이미지를 보고 분석하여 대화를 할 수 있다. API에서 citations flag가 필요하며, 없을 경우 텍스트 추출만 이루어진다.\n",
    "- 작동 원리는\n",
    "    - PDF에서 각 페이지를 이미지로 바꾼다.\n",
    "    - 텍스트 또한 추출하여 페이지 이미지와 함께 입력으로 들어가고\n",
    "    - 추출 텍스트와 페이미 이미지를 참고하여 답변을 생성한다.\n",
    "    - 반복적 입력에 대해 최적화 위해 prompt caching 기능을 제공한다.\n",
    "    ```JSON\n",
    "    {\n",
    "        \"type\": \"document\",\n",
    "        \"source\": {\n",
    "            \"type\": \"base64\",\n",
    "            \"media_type\": \"application/pdf\",\n",
    "            \"data\": $PDF_BASE64\n",
    "        },\n",
    "        {\n",
    "            \"cache_control\": {\n",
    "                \"type\": \"ephemeral\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "    - batch api에서 또한 사용할 수 있다.\n",
    "- 가격은\n",
    "    - 텍스트 토큰에 대해 부가되고\n",
    "    - 역시 페이지 이미지에 대해서도 요금이 부가된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9277135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "CLAUDE_API_KEY = os.getenv(\"CLAUDE_API_KEY\")\n",
    "\n",
    "client = Anthropic(api_key=CLAUDE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1254f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.messages.create(\n",
    "    model=\"claude-sonnet-4-5\",\n",
    "    max_tokens=64000,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"document\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"url\",\n",
    "                        \"url\": \"https://arxiv.org/pdf/2411.13768\"\n",
    "                    },\n",
    "                    \"cache_control\": {\n",
    "                        \"type\": \"ephemeral\"\n",
    "                    },\n",
    "                    \"citations\": {\n",
    "                        \"enabled\": True\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": [{\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Markdown형태로 변환하고, AI Engineer가 쉽게 이해할 수 있도록 번역해줘\"\n",
    "            }]\n",
    "        }\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "events = []\n",
    "for event in response:\n",
    "    events.append(event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dc016a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# LLM 에이전트의 평가 주도 개발 및 운영: 프로세스 모델과 참조 아키텍처\n",
      "\n",
      "## 초록\n",
      "\n",
      "대규모 언어 모델(LLM)은 명확하지 않은 목표를 추구하고 배포 후 적응할 수 있는 시스템인 LLM 에이전트의 등장을 가능하게 했습니다. 이러한 에이전트를 평가하는 것은 그들의 행동이 개방형이고, 확률적이며, 시간에 따른 시스템 수준의 상호작용에 의해 형성되기 때문에 어렵습니다. 고정된 벤치마크와 정적 테스트 스위트를 중심으로 구축된 전통적인 평가 방법은 창발적 행동을 포착하지 못하고 라이프사이클 전반에 걸친 지속적인 적응을 지원하지 못합니다.\n",
      "\n",
      "보다 체계적인 접근을 위해, 우리는 학술 및 산업 평가 관행을 종합하는 다성적 문헌 검토(MLR)를 수행했습니다. 이 연구 결과는 평가를 최종 체크포인트가 아닌 지속적이고 관리하는 기능으로 포함시키는 두 가지 경험적으로 도출된 아티팩트인 프로세스 모델과 참조 아키텍처를 직접적으로 알려줍니다. 이들은 함께 오프라인(개발 시간) 및 온라인(런타임) 평가를 폐쇄 피드백 루프 내에서 통합하는 평가 주도 개발 및 운영(EDDOps) 접근 방식을 구성합니다. 평가 증거가 런타임 적응과 관리된 재개발 모두를 주도하게 함으로써, EDDOps는 변화하는 목표, 사용자 요구 및 거버넌스 제약과 일치하는 LLM 에이전트의 더 안전하고 추적 가능한 진화를 지원합니다.\n",
      "\n",
      "**키워드**: 에이전트, 에이전틱, AgentOps, 대규모 언어 모델, 기반 모델, 평가, 운영, 프로세스 모델, 참조 아키텍처\n",
      "\n",
      "## 1. 서론\n",
      "\n",
      "대규모 언어 모델(LLM)의 최근 발전은 복잡한 작업을 자율적으로 수행할 수 있는 LLM 기반 에이전트(LLM 에이전트)의 등장으로 이어졌습니다(예: AI Scientist). 사전 정의된 입력과 구조화된 작업 실행에 의존하는 전통적인 AI/LLM 시스템과 달리, LLM 에이전트는 높은 수준의 명확하지 않은 사용자 목표를 동적으로 해석합니다. 그들은 맥락을 인식하고, 추론하고, 계획하고, 워크플로우를 실행하며, 종종 외부 도구, 지식 베이스 및 다른 에이전트를 통합하여 기능을 확장합니다.\n",
      "\n",
      "증가하는 채택에도 불구하고, LLM 에이전트는 성능과 안전성에 대한 우려를 제기합니다. 그들의 개방형 추론, 계획 및 실행은 특히 모호함, 새로운 시나리오 또는 진화하는 맥락 하에서 작업 성능 저하(예: 목표 표류, 도구 오용 또는 추론 오류) 및 안전 문제(예: 해로운 출력, 개인정보 침해 또는 규제 위반)를 초래할 수 있습니다. 따라서 엄격하고 지속적인 평가는 LLM 에이전트가 예상대로 작동하고 시간이 지남에 따라 안전하게 진화하도록 보장하는 데 필수적입니다.\n",
      "\n",
      "### 평가의 과제\n",
      "\n",
      "LLM 및 LLM 에이전트를 위한 벤치마킹 및 테스팅 프레임워크에 대한 연구가 확장되고 있지만, 대부분의 기존 접근 방식은 모델 수준의 행동, 표준화된 벤치마크, 정적 데이터셋 및 집계된 점수에 초점을 맞춥니다. 이러한 프레임워크는 중간 아티팩트와 장기 워크플로우에 대한 제한된 가시성을 제공하며, 특정 작업 슬라이스, 사용자 코호트 또는 운영 컨텍스트에 대한 세밀한 분석을 거의 지원하지 않아 성능 드리프트나 새로운 위험을 탐지할 수 없습니다. 또한 행동 추적을 수집하는 런타임 관찰 가능성 시스템이나 안전 또는 규정 준수 제약을 시행하는 정책 메커니즘과 거의 연결되지 않습니다. 결과적으로 운영 중 시스템 수준 평가의 전체 범위를 다루지 못합니다.\n",
      "\n",
      "테스트 주도 개발(TDD) 및 행동 주도 개발(BDD)과 같은 고전적인 소프트웨어 엔지니어링 방법도 이 설정에서 한계가 있습니다. 이러한 방법은 안정적인 사양, 실행 가능한 오라클 및 주로 배포 전 테스트 단계를 가정합니다. 반면, LLM 에이전트는 비결정적이고, 명확하지 않은 목표를 추구하며, 배포 후에도 계속 적응합니다. 그들의 결과는 등급화되거나 비교적일 수 있으며, 판정에는 플러그 가능한 심사자나 인간의 감독이 필요할 수 있습니다. 따라서 기존 벤치마크와 테스팅 프레임워크나 TDD/BDD 단독으로는 LLM 에이전트가 요구하는 지속적이고 라이프사이클 전반에 걸친 평가와 거버넌스를 제공할 수 없습니다.\n",
      "\n",
      "### EDDOps 접근 방식\n",
      "\n",
      "이러한 과제를 해결하기 위해, 이 논문은 TDD와 BDD의 반복적 원칙을 기반으로 하면서 LLM 에이전트의 독특한 요구에 적응시킨 평가 주도 개발 및 운영(EDDOps) 접근 방식을 소개합니다. 이 논문에서 EDDOps는 오프라인과 온라인 모두의 평가 증거를 규율적으로 사용하여 에이전트 런타임 및 후속 (재)개발 중 대상 변경의 우선순위를 정하고 관리하는 것을 의미합니다.\n",
      "\n",
      "EDDOps는 LLM 에이전트의 전체 라이프사이클 전반에 걸쳐 지속적인 피드백 루프를 포함합니다. 그러나 주로 배포 전 단계에 적용되고 상대적으로 안정적인 사양과 결정론적 테스트 결과를 가정하는 TDD 및 BDD와 달리, EDDOps는 LLM 에이전트의 특징인 비결정론적 행동과 배포 후 진화를 다루어야 합니다. 이를 통해 평가를 진화하는 목표와 운영 맥락과의 지속적인 개선 및 정렬을 지원하는 동적이고 통합적인 기능으로 위치시킵니다.\n",
      "\n",
      "## 연구 질문\n",
      "\n",
      "연구는 다음 연구 질문(RQ)을 중심으로 구조화되어 있습니다:\n",
      "\n",
      "1. **RQ1: LLM 에이전트를 라이프사이클 전반에 걸쳐 평가하는 데 있어 주요 과제는 무엇인가?** 이 질문을 다루기 위해 LLM 에이전트의 현재 평가 환경에 대한 MLR을 수행합니다. 검토는 기존 관행의 격차를 식별하기 위해 맥락, 방법론적 접근 방식 및 아키텍처 고려사항을 포함한 주요 평가 차원을 조사합니다.\n",
      "\n",
      "2. **RQ2: 평가를 LLM 에이전트의 라이프사이클에 절차적으로 통합하는 방법은?** MLR 데이터와 RQ1 통찰력을 기반으로, 라이프사이클 전반에 걸쳐 평가를 체계적으로 포함하는 구조화된 프로세스 모델을 제안합니다. 이 모델은 오프라인 및 온라인 평가를 가능하게 하여 런타임과 (재)개발 중 대상 개선을 지원합니다.\n",
      "\n",
      "3. **RQ3: 평가를 LLM 에이전트의 라이프사이클에 아키텍처적으로 통합하는 방법은?** MLR 데이터와 RQ1/RQ2 발견을 기반으로, 에이전트의 설계 내에 평가를 포함하는 참조 아키텍처를 설계합니다. 이 아키텍처는 온라인 및 오프라인 평가를 모두 지원하는 데 필요한 기술 인프라를 제공하여 에이전트의 증거 기반 개선을 가능하게 합니다.\n",
      "\n",
      "## 2. 배경 및 관련 연구\n",
      "\n",
      "### 2.1 기존 LLM 에이전트 평가 방법\n",
      "\n",
      "기존 평가 프레임워크는 주로 모델 수준에 초점을 맞추며, 코딩, 의료, 법률, 금융과 같은 영역에서 LLM 기능을 평가합니다. 그러나 이러한 벤치마크는 일반적으로 고정된 입력, 정적 데이터셋 및 집계된 점수를 가정하며, 복잡한 다중 구성 요소 에이전트에서 발생하는 시스템 수준의 사회기술적 상호작용을 설명하지 않는 경우가 많습니다.\n",
      "\n",
      "많은 LLM 에이전트 평가 방법은 여전히 고정되거나 주기적으로 업데이트되는 벤치마크에 크게 의존합니다. 정적 테스트는 데이터 오염의 위험이 있으며 실제 애플리케이션의 동적이고 진화하는 맥락에 적응하지 못합니다. 실시간 또는 주기적으로 새로고침되는 벤치마크는 시간이 지남에 따라 작업을 업데이트하여 이러한 문제 중 일부를 완화하지만, 일반적으로 운영 환경 내에서의 현장, 실시간 평가를 가능하게 하는 데는 미치지 못합니다. 결과적으로 고정 및 주기적으로 업데이트되는 벤치마크 모두 실용적이고 실시간 설정에서 LLM 에이전트의 전체 복잡성과 창발적 행동을 포착하는 데 어려움을 겪습니다.\n",
      "\n",
      "### 2.2 평가로부터의 학습\n",
      "\n",
      "평가 결과를 활용하여 에이전트 행동을 개선하려는 연구가 증가하고 있습니다: 경험(로그된 궤적, 미래 상태, 도구 피드백과 같은)과 평가된 증거(진단, 구조화된 검사, 보상 신호와 같은). 평가가 적응으로 어떻게 공급될 수 있는지 강조하고 EDDOps가 다루고자 하는 남은 격차를 드러내기 위해 가장 관련성 있는 방향을 아래에 그룹화합니다.\n",
      "\n",
      "주요 연구 방향:\n",
      "- **경험 인식 강화 및 재생**: 이전 궤적을 재사용하고 강한 학습 신호를 제공하는 궤적을 우선적으로 학습\n",
      "- **보상 없는 초기 경험**: 명시적 인간 보상 없이 에이전트의 관찰된 결과를 감독으로 사용\n",
      "- **환경 및 커리큘럼 형성**: 에이전트가 아닌 훈련 또는 평가 환경 조정\n",
      "- **런타임 자기 적응 및 자기 성찰**: 모델 가중치 변경 없이 런타임에서 적응\n",
      "- **시스템 수준 실패 분석**: 시스템 파이프라인을 진단의 대상으로 취급\n",
      "\n",
      "우리의 EDDOps 작업은 보완적입니다. 우리는 평가를 설계 시간, 빌드 시간 및 런타임 운영에 걸쳐 있는 일급 시스템 기능으로 취급합니다.\n",
      "\n",
      "### 2.3 TDD/BDD와 EDDOps 비교\n",
      "\n",
      "TDD와 BDD는 상대적으로 안정적이고 잘 정의된 사양을 가진 소프트웨어 시스템의 정확성과 이해관계자 정렬을 보장하기 위한 확립된 방법론입니다. TDD는 구현 전에 자동화된 테스트를 작성하여 red-green-refactor 주기를 시행하도록 장려하고, BDD는 이해관계자 정의 시나리오(예: Given-When-Then)를 통해 시스템 행동을 검증하여 공유 이해를 촉진합니다.\n",
      "\n",
      "**표 1: LLM 에이전트를 위한 TDD, BDD 및 EDDOps 비교**\n",
      "\n",
      "| 측면 | TDD | BDD | EDDOps |\n",
      "|------|-----|-----|---------|\n",
      "| 범위 | 배포 전(오프라인) | 배포 전(오프라인) | 전체 라이프사이클(오프라인 및 온라인) |\n",
      "| 요구사항 | 정적, 명시적 | 이해관계자 정의 시나리오 | 진화하는, 맥락 기반 |\n",
      "| 접근 방식 | 단위 테스트, 이진 단언 | 수락 테스트, 시나리오 검사 | 지속적이고 적응적 평가; 온라인 및 오프라인 모두 |\n",
      "| 피드백 소스 | 개발자 | 이해관계자 | 온라인/오프라인 AI/인간 평가자 |\n",
      "| 적응성 | 낮음(수동 테스트 업데이트) | 중간(시나리오 수정) | 높음(평가 기반 개선) |\n",
      "| 검증 초점 | 코드 수준 정확성 | 시나리오에 대한 행동 | 시스템 수준 성능 및 안전 |\n",
      "\n",
      "## 3. 방법론\n",
      "\n",
      "이 연구는 확립된 지침에 따라 LLM 에이전트 평가에 대한 학술 및 산업 소스의 통찰력을 종합하기 위해 다성적 문헌 검토(MLR)를 사용합니다. MLR은 평가 관행이 연구 및 산업 환경에서 빠르게 진화하고 주요 방법, 도구 및 프레임워크가 종종 기술 보고서, 프리프린트 또는 실무자 아티팩트로 문서화되기 때문에 이 주제에 특히 적합합니다. 이러한 상호 보완적 소스를 통합함으로써, 검토는 실제 시스템에서 평가가 수행되는 방식을 형성하는 이론적 기반과 운영 관행을 모두 포착합니다.\n",
      "\n",
      "### MLR 프로세스\n",
      "\n",
      "연구는 다음 단계로 진행되었습니다:\n",
      "\n",
      "1. **계획**: 연구 프로토콜 개발 및 파일럿 연구\n",
      "2. **키워드 검색**: 학술 및 그레이 문헌 검색\n",
      "3. **선별 및 선택**: 포함/제외 기준에 따른 문헌 선별\n",
      "4. **확장 검색**: 역방향 및 순방향 스노우볼링\n",
      "5. **품질 평가**: 학술적 엄격성 및 실무적 타당성 평가\n",
      "6. **데이터 추출 및 합성**: 주제 분석 및 패턴 식별\n",
      "\n",
      "최종 데이터셋은 134개의 학술 소스와 27개의 도구, 프레임워크 및 플랫폼으로 구성되었습니다.\n",
      "\n",
      "### 증거 기반 설계 도출\n",
      "\n",
      "MLR에서 종합된 발견 사항은 평가 수명 주기 및 시스템 구조에 대한 함의로 직접 관련되었습니다. 합성에서 식별된 각 반복 과제 및 설계 동인에 대해 기존 시스템이 이를 해결하려고 시도하거나 해결하지 못한 방법을 조사하고, 평가 중심 수명 주기 및 에이전트 스택이 이에 대응하기 위해 필요한 절차적 책임과 구조적 지원을 추상화했습니다. 각 함의는 평문으로 표현된 짧고 실행 가능한 설계 동인으로 포착되었습니다(예: \"의미 있는 인간 감독\"). 저자들은 이러한 동인을 기본 코딩된 발췌문과 함께 사용하여 두 가지 상호 보완적 아티팩트를 형성했습니다:\n",
      "\n",
      "- **프로세스 모델 형성**: 절차적 책임을 부과하는 동인을 수명 주기 활동으로 그룹화\n",
      "- **참조 아키텍처 형성**: 지속적인 구조 또는 인터페이스를 요구하는 동인을 아키텍처 요소로 그룹화\n",
      "\n",
      "## 4. RQ1: MLR 결과 및 핵심 사항\n",
      "\n",
      "### 4.1 LLM 에이전트 평가의 과제\n",
      "\n",
      "#### 4.1.1 단편화된 라이프사이클 커버리지\n",
      "\n",
      "학술 소스는 배포 전 평가에 크게 치우쳐 있으며(125/134, 93.28%), 배포 후(3/134, 2.24%) 또는 지속적 평가(6/134, 4.48%)를 다루는 경우는 훨씬 적습니다. 반면, 그레이 문헌은 상대적으로 더 균형 잡힌 분포를 보입니다: 12/27(44.44%) 배포 전, 4/27(14.81%) 배포 후, 11/27(40.74%) 지속적. 이는 산업 주도 관행이 지속적인 모니터링의 필요성을 인식하고 있음을 시사하지만, 배포 후 평가는 그레이 소스에서도 여전히 과소 대표되어 있습니다.\n",
      "\n",
      "**해석적 요점**:\n",
      "- 운영상의 맹점\n",
      "- 깨진 피드백\n",
      "- 시간이 지남에 따라 악화되는 보증\n",
      "\n",
      "#### 4.1.2 집계된 메트릭에 대한 과도한 의존\n",
      "\n",
      "학술 소스는 압도적으로 종단 간 메트릭을 사용하며(124/134, 92.54%), 중간 전용 메트릭(5/134, 3.73%) 또는 혼합 메트릭(4/134, 2.99%)을 사용하는 경우는 매우 드뭅니다. 이 분포는 순전히 집계된 결과가 학술 샘플의 지배적인 주요 초점이며 중간 또는 혼합 보고가 드물다는 것을 보여줍니다.\n",
      "\n",
      "그레이 문헌 하위 집합에서는 혼합 메트릭이 가장 일반적입니다(22/27, 81.48%). 소수는 종단 간 메트릭만 사용하며(3/27, 11.11%), 중간 전용 메트릭을 사용하는 경우는 없으며(0/27, 0%), 두 소스(2/27, 7.41%)는 메트릭을 보고하지 않고 대신 관찰 가능성 인프라로 기능합니다.\n",
      "\n",
      "**해석적 요점**:\n",
      "- 집계 전용 뷰는 진단을 제한\n",
      "- 중간 평가에는 트레이드오프가 있음\n",
      "- 혼합 메트릭은 세부 사항과 유용성의 균형을 맞춤\n",
      "\n",
      "#### 4.1.3 모델 수준과 시스템 수준 평가 간의 격차\n",
      "\n",
      "학술 소스는 주로 모델 수준에서 평가하며(89/134, 66.42%), 시스템 수준(29/134, 21.64%)과 통합 평가를 사용하는 경우는 더 적습니다(16/134, 11.94%).\n",
      "\n",
      "반면, 그레이 문헌은 더 시스템 인식 관점을 채택합니다. 통합 평가가 더 일반적이며(15/27, 55.56%), 시스템 수준 평가는 8/27(29.63%), 모델 전용 평가는 4/27(14.81%)입니다.\n",
      "\n",
      "**해석적 요점**:\n",
      "- 모델 전용 초점은 시스템 행동을 가릴 수 있음\n",
      "- 시스템 수준 평가는 오케스트레이션 결함을 드러냄\n",
      "- 통합 평가는 수정을 실제 결과와 일치시킴\n",
      "\n",
      "#### 4.1.4 적응형 평가 부족\n",
      "\n",
      "학술 소스는 주로 정적입니다(131/134, 97.76%), 적응형은 매우 적습니다(3/134, 2.24%).\n",
      "\n",
      "그레이 문헌 하위 집합에서 정적 평가가 여전히 다수이지만(22/27, 81.48%), 적응형 평가가 학술 샘플보다 더 일반적입니다(5/27, 18.52%).\n",
      "\n",
      "#### 4.1.5 개선을 위한 평가 활용 실패\n",
      "\n",
      "학술 샘플에서 39/134(29.10%)가 평가를 활용하고 95/134(70.90%)는 체크포인트 전용입니다.\n",
      "\n",
      "그레이 문헌 하위 집합에서 22/27(81.48%)이 평가를 활용하고 5/27(18.52%)는 체크포인트 전용입니다.\n",
      "\n",
      "#### 4.1.6 AI 전용 평가의 한계\n",
      "\n",
      "학술 소스는 주로 AI 전용 평가자를 사용하며(118/134, 88.06%), 하이브리드 인간-AI 평가자를 사용하는 경우(12/134, 8.96%)와 인간 주도 평가를 사용하는 경우(4/134, 2.99%)는 더 적습니다.\n",
      "\n",
      "그레이 문헌 하위 집합에서 AI 전용과 하이브리드 인간-AI 평가자가 동등하게 일반적이며(각각 12/27, 44.44%), 인간 주도 평가는 소수의 소스에 나타납니다(3/27, 11.11%).\n",
      "\n",
      "### 4.2 교차 평가 동인(D1-D6)\n",
      "\n",
      "MLR 결과를 종합하여 6가지 평가 동인을 도출했습니다:\n",
      "\n",
      "- **D1 라이프사이클 커버리지**: 배포 전, 배포 후 및 지속적 운영에 걸친 평가\n",
      "- **D2 집계를 넘어선 메트릭 믹스**: 종단 간 결과와 중간, 단계 수준 및 슬라이스 인식 검사의 결합\n",
      "- **D3 시스템 수준 앵커**: 시스템 행동과 오케스트레이션에 고정된 평가\n",
      "- **D4 적응형 평가**: 안정적인 기준선과 위험 또는 신호 기반 프로브 포함\n",
      "- **D5 폐쇄 피드백 루프**: 구체적인 조치와 연결된 오프라인 및 온라인 평가 결과\n",
      "- **D6 의미 있는 인간 감독**: 자동화된 평가자가 일상적인 사례를 처리하고 인간이 모호하거나 영향력이 큰 사례에 대한 평가 권한을 유지하는 하이브리드 판단 패턴\n",
      "\n",
      "## 5. LLM 에이전트 평가를 위한 프로세스 모델\n",
      "\n",
      "MLR 데이터와 교차 평가 동인(D1-D6)을 기반으로, LLM 에이전트 평가를 위한 구조화된 프로세스 모델을 소개합니다. 이 모델은 MLR에서 관찰된 공통 패턴과 격차를 반영하고 오프라인 및 온라인 컨텍스트 전반에 걸쳐 지속적인 모니터링과 개선을 지원하는 라이프사이클 전반, 위험 인식 및 적응형 평가 프로세스로 형식화합니다. 이는 오프라인 및 온라인 평가, 구조화된 피드백 루프 및 간단한 인간 참여 정책을 통합하여 평가를 최종 체크포인트가 아닌 개발 및 운영 모두의 동인으로 만듭니다.\n",
      "\n",
      "### 5.1 1단계: 평가 계획 정의 (D1, D2, D3; D4, D6 활성화)\n",
      "\n",
      "**주요 입력**:\n",
      "- 사용자 목표: 의도된 행동과 맥락을 정의하는 높은 수준의 목표와 성공 기준\n",
      "- 거버넌스 요구사항: 범위와 임계값을 형성하는 법적, 윤리적 및 안전 제약\n",
      "- 초기 에이전트 아키텍처: 시스템의 구조적 및 행동적 청사진\n",
      "\n",
      "**프로세스 단계**:\n",
      "1. 사용자 목표 이해\n",
      "2. 거버넌스 요구사항 통합\n",
      "3. 초기 에이전트 아키텍처 분석\n",
      "4. 위험 기반 우선순위 지정\n",
      "5. 평가 계획 생성\n",
      "\n",
      "**주요 출력**:\n",
      "- 평가 범위 및 목적\n",
      "- 평가 전략 및 방법론\n",
      "- 평가 기준 및 메트릭\n",
      "- 예비 안전 사례\n",
      "\n",
      "### 5.2 2단계: 평가 테스트 케이스 개발 (D2, D3, D4)\n",
      "\n",
      "**주요 입력**:\n",
      "- 평가 계획\n",
      "- 과거 평가 결과\n",
      "- 도메인 지식 베이스\n",
      "\n",
      "**프로세스 단계**:\n",
      "1. 평가 벤치마크 및 프레임워크 식별\n",
      "2. 도메인 지식 베이스 수집\n",
      "3. 도메인 전문가와 함께 테스트 데이터 큐레이션\n",
      "4. LLM으로 합성 테스트 데이터 생성\n",
      "\n",
      "**주요 출력**:\n",
      "- 버전 관리된 테스트 카탈로그\n",
      "- 포괄적인 테스트 스위트\n",
      "- 선택된 벤치마크 및 프레임워크\n",
      "\n",
      "### 5.3 3단계: 오프라인 및 온라인 평가 수행 (D1, D2, D3, D4, D6)\n",
      "\n",
      "**주요 입력**:\n",
      "- 식별된 벤치마크\n",
      "- 테스트 케이스\n",
      "- 평가 프레임워크\n",
      "\n",
      "**프로세스 단계**:\n",
      "1. 최종 결과 평가\n",
      "2. 중간 파이프라인 및 아티팩트 평가\n",
      "\n",
      "**출력**:\n",
      "- 오프라인 평가: 기준 메트릭, 오류 분석 및 통과/실패 요약\n",
      "- 온라인 평가: 사용자 영향, 적응형 응답 및 행동 패턴\n",
      "- 실행 가능한 피드백: 영향을 받는 슬라이스, 예시 궤적, 제안된 프로브\n",
      "\n",
      "### 5.4 4단계: 분석 및 개선 (D5; D1-D4, D6 활성화)\n",
      "\n",
      "**주요 입력**:\n",
      "- 시스템 수준 평가 결과 (3단계에서)\n",
      "- 모델 평가 결과\n",
      "\n",
      "**프로세스 단계**:\n",
      "1. 런타임 중 개선 (온라인): 사전 설정된 제한 하에서 영향을 받는 슬라이스에 제한된 조정 적용\n",
      "2. 재개발 중 개선 (오프라인): 문제가 런타임 범위를 초과하거나 재발하는 경우 관리된 설계 변경 도입\n",
      "\n",
      "**출력**:\n",
      "- 안전 사례: 위험 주장 및 통제와 슬라이스 수준 증거를 연결하는 업데이트된 안전 사례\n",
      "- 개선된 에이전트 아키텍처\n",
      "- 업데이트된 LLM (해당하는 경우)\n",
      "- 개선된 파이프라인/아티팩트\n",
      "\n",
      "## 6. EDDOps 참조 아키텍처\n",
      "\n",
      "RQ3를 다루기 위해, MLR 발견과 교차 평가 동인(D1-D6)을 분석적으로 일반화하고 섹션 5의 프로세스 모델을 보완하는 참조 아키텍처를 제안합니다. 경험적으로 근거한 참조 아키텍처의 원칙과 일치하게, 이 아키텍처는 도메인 특정 세부 사항을 추상화하면서도 섹션 3.3에 설명된 코딩된 증거와 설계 동인에 연결된 상태로 유지하는 산업 교차, 예비 촉진 참조 아키텍처로 위치합니다.\n",
      "\n",
      "아키텍처는 평가 우선 입장을 채택합니다: 평가 백본 및 제어 루프는 오프라인 및 온라인 평가를 개발 및 운영 중 변경을 주도하기 위해 연결하며(D1-D5), 하이브리드 감독(D6)과 함께 평가를 최종 체크포인트가 아닌 일급 책임으로 포함합니다.\n",
      "\n",
      "### 주요 원칙\n",
      "\n",
      "설계는 MLR에서 관찰된 패턴을 기반으로 한 세 가지 주요 원칙에 의해 안내됩니다:\n",
      "\n",
      "- **라이프사이클 통합 (D1)**: 평가는 배포 전과 배포 후에 걸쳐 있으며 에이전트 라이프사이클 전반에 걸쳐 지속적인 가시성과 개선을 가능하게 합니다.\n",
      "- **변화의 동인으로서의 평가 (D5)**: 발견 사항은 제한된 런타임 조정과 관리된 재개발을 인스턴스화하며 정적 보고서가 아닌 증거 연결 변경으로 기록됩니다.\n",
      "\n",
      "### 아키텍처 계층\n",
      "\n",
      "아키텍처는 세 가지 주요 계층으로 구성됩니다:\n",
      "\n",
      "1. **공급망 계층**: 평가 의도 및 증거 기반 수립\n",
      "   - 계획 및 설계\n",
      "   - 데이터 수집 및 생성\n",
      "   - 모델 구축/선택 및 평가\n",
      "   - 시스템 구축 및 평가\n",
      "\n",
      "2. **에이전트 계층**: 시스템 수준 평가 표면 노출\n",
      "   - 외부 환경 (사용자, 다른 에이전트, 도구, 지식 베이스)\n",
      "   - 에이전트 모듈 (컨텍스트 엔진, 추론 및 계획, 워크플로우 실행, 다층 가드레일, 메모리)\n",
      "\n",
      "3. **운영 계층**: 지속적인 평가 및 적응의 중심\n",
      "   - 평가 (백본 및 제어 루프)\n",
      "   - AgentOps 인프라 및 관찰 가능성\n",
      "\n",
      "### 평가 백본 및 제어 루프\n",
      "\n",
      "평가 백본은 라이프사이클 전반에 걸쳐 생성된 증거를 통합하고 두 가지 상호 보완적 경로를 통해 라우팅합니다:\n",
      "\n",
      "**오프라인 개선 경로 (개발 시간) (D1, D2, D3, D5)**: 배치 평가가 평가 결과에 저장된 증거를 생성합니다. 이러한 결과는 설계/개발 아티팩트로 흐르며 시스템 아티팩트 및 파이프라인 업데이트를 지원합니다. 각 변경은 버전 관리되어야 하며 재배포 전에 재평가가 루프를 닫도록 원래 증거와 연결되어야 합니다.\n",
      "\n",
      "**온라인 적응 경로 (운영 시간) (D1, D2, D4, D6)**: 관찰 가능성 신호 또는 예약된 프로브에 의해 트리거된 런타임 평가가 AgentOps에 실시간 피드백을 제공합니다. 사전 정의된 거버넌스 경계 내에서 이러한 결과는 재배포 없이 프롬프트, 라우팅 정책 또는 가드레일 임계값을 조정할 수 있습니다. 더 큰 영향을 미치는 변경은 오프라인 경로로 연기됩니다.\n",
      "\n",
      "## 7. 경험적 검증\n",
      "\n",
      "이 섹션은 우리 기여의 목적 적합성 검증을 제공합니다. 프로세스 모델과 참조 아키텍처가 MLR에서 직접 경험적으로 도출되었기 때문에, 여기서의 목표는 경험적 기반을 재확립하는 것이 아니라 의도된 목적에 유용하고 적절한지 확인하는 것입니다. Galster와 Angelov를 따라, 이는 실험적이 아닌 분석적 및 인스턴스화 기반 검증을 구성합니다.\n",
      "\n",
      "### 7.1 MLR의 방법론적 건전성\n",
      "\n",
      "- **내부 타당성**: 명시적 포함/제외 기준, 조정과 함께 이중 스크리닝, 문서화된 코딩 프로토콜\n",
      "- **외부 타당성**: 학술(n=134) 및 그레이(n=27) 소스에 걸친 말뭉치\n",
      "- **구성 타당성**: 라이프사이클 커버리지, 메트릭 믹스, 시스템 수준 앵커링과 같은 개념을 교차 평가 동인(D1-D6)으로 운영화\n",
      "\n",
      "### 7.2 프로세스 모델의 적용 가능성\n",
      "\n",
      "#### 7.2.1 사례 연구: LLM 기반 세무 어시스턴트\n",
      "\n",
      "모델은 오스트레일리아 과세청 자료에 대한 인용 지원 지침을 제공하는 LLM 기반 세무 어시스턴트의 배포 전 설정에서 인스턴스화되었습니다. 이 연습은 계획, 오프라인 평가 및 개선 제안을 다루었습니다(프로덕션 롤아웃 없음).\n",
      "\n",
      "- **1단계 (계획)**: 목표, 거버넌스 제약 및 높은 수준의 아키텍처 정의\n",
      "- **2단계 (테스트 케이스 준비)**: 중립적인 평가 프레임워크 선택 및 도메인 케이스 큐레이션\n",
      "- **3단계 (평가)**: 종단 간 및 단계 수준 지표 측정을 위한 오프라인 배치 실행\n",
      "- **4단계 (개선)**: 프롬프트 또는 쿼리 조정 및 가드레일 개선을 위한 증거 연결 티켓 생성\n",
      "\n",
      "#### 7.2.2 실무자 삼각 측량\n",
      "\n",
      "실무자 소스는 프로세스 모델과 일치하는 메커니즘이 이미 실제로 사용되고 있음을 확인하며 주요 단계와 밀접하게 매핑됩니다: 해석 가능한 계획 및 명확한 오라클, 진화하는 벤치마크 (정적 스위트 아님), 쌍을 이룬 오프라인/온라인 평가, 캘리브레이션을 통한 하이브리드 감독, 폐쇄 루프 개선 및 보호된 롤아웃.\n",
      "\n",
      "### 7.3 참조 아키텍처의 아키텍처 적절성\n",
      "\n",
      "#### 7.3.1 비교 분석\n",
      "\n",
      "우리 아키텍처는 평가를 일급 책임으로 만들어 이전 책임 있는 AI 및 FM 에이전트 설계를 확장합니다. 이전 아키텍처에서 평가는 하나의 구성 요소 또는 패턴(예: 지속적인 RAI 검증자)으로 나타나는 반면, 여기서는 라이프사이클 및 운영 전반에 걸쳐 D1-D6를 실현하는 구조적 제어 백본으로 취급됩니다.\n",
      "\n",
      "**표 3: 비교 분석**\n",
      "\n",
      "| 차원 | 책임 있는 AI 시스템 설계 | FM 에이전트 설계 | EDDOps 아키텍처 |\n",
      "|------|-------------------------|-----------------|----------------|\n",
      "| 범위 | 시스템 설계를 위한 책임 있는 AI 원칙 | 기반 모델 기반 자율 에이전트 | LLM 에이전트의 평가 주도 개발 및 운영 |\n",
      "| 모듈성 | 규정 준수 및 거버넌스 모듈 | 자율성 지향, 조정 모듈 | 플러그 가능한 평가자, 리포지토리 및 관찰 가능성 제어 |\n",
      "| 평가 통합 | 감사를 위한 지속적인 RAI 검증자 패턴 | 위험/거버넌스를 위한 지속적 평가 | 오프라인/온라인 루프를 연결하는 평가 백본 |\n",
      "\n",
      "#### 7.3.2 분석적 검증\n",
      "\n",
      "ISO/IEC 25010 품질 특성에 대한 아키텍처 평가:\n",
      "\n",
      "- **기능적 적합성**: 완전한 평가 기능 세트\n",
      "- **성능 효율성**: 중앙 집중식 모니터링 및 확장 가능한 평가\n",
      "- **호환성**: 명시적 인터페이스를 통한 계층화된 구조\n",
      "- **상호 작용 가능성**: 소비 가능한 평가 아티팩트\n",
      "- **신뢰성**: 결함 감지 및 제어된 복구를 위한 폐쇄 루프\n",
      "- **보안**: 버전 관리된 증거 저장소로서의 가드레일 및 평가 결과\n",
      "- **유지 관리성**: 모듈식 책임 분리\n",
      "- **유연성**: 도메인 및 트래픽 수준에 걸친 플러그 가능한 구성 요소\n",
      "- **안전**: 위험 인식 계획 및 다층 가드레일\n",
      "\n",
      "## 8. 결론\n",
      "\n",
      "이 논문은 LLM 에이전트의 라이프사이클 전반에 걸쳐 평가를 지속적이고 관리하는 기능으로 포함시키기 위한 경험적으로 근거한 접근 방식인 EDDOps를 제시했습니다. 세 가지 연구 질문에 의해 안내되어, 평가 주도 개발 및 운영에 대한 이해와 실무를 모두 발전시켰습니다. MLR(RQ1)을 통해 단편화된 라이프사이클 커버리지, 집계 메트릭에 대한 과도한 의존, 제한된 적응성 및 불충분한 인간 감독을 포함한 기존 평가 관행의 반복적인 한계를 식별하고 이러한 발견을 교차 평가 동인으로 정제했습니다. 이러한 동인은 MLR 데이터와 함께 두 가지 아티팩트를 직접 제약하고 알렸습니다: 추적 가능한 피드백 루프를 통해 계획, 평가 및 개선을 연결하여 지속적인 평가를 절차적으로 포함하는 프로세스 모델(RQ2)과 관찰 가능성, 하이브리드 감독 및 증거 기반 변경 제어로 지원되는 오프라인 및 온라인 루프를 연결하는 백본으로 평가를 구조적으로 실현하는 참조 아키텍처(RQ3). 함께, 프로세스 모델과 참조 아키텍처는 평가를 최종 체크포인트가 아닌 적응형 개선을 주도하고, 안전과 책임성을 유지하며, 동적 환경에서 LLM 에이전트의 책임 있는 진화를 지원하는 지속적인 시스템 기능으로 위치시킵니다.\n"
     ]
    }
   ],
   "source": [
    "text = ''\n",
    "for event in events:\n",
    "    if event.type == \"content_block_delta\" and event.delta.type == \"text_delta\":\n",
    "        text += event.delta.text\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6378a1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RawMessageStartEvent(message=Message(id='msg_01919M9F1RXJUp2woBkCCgep', content=[], model='claude-sonnet-4-5-20250929', role='assistant', stop_reason=None, stop_sequence=None, type='message', usage=Usage(cache_creation=CacheCreation(ephemeral_1h_input_tokens=0, ephemeral_5m_input_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=88842, output_tokens=1, server_tool_use=None, service_tier='standard')), type='message_start')\n",
      "RawMessageDeltaEvent(delta=Delta(stop_reason='end_turn', stop_sequence=None), type='message_delta', usage=MessageDeltaUsage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=88842, output_tokens=14102, server_tool_use=None))\n"
     ]
    }
   ],
   "source": [
    "print(events[0])\n",
    "print(events[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2faf4a",
   "metadata": {},
   "source": [
    "- 따로 PDF 파일에 대해 전처리가 필요없기 때문에 편하다.\n",
    "- citation flag는 messages.content 내부에서 설정할 수 있다.\n",
    "- response.usage에서 'cache_read_input_tokens' 필드가 있는 것으로 보아, input 문서가 캐싱된 듯하다. \n",
    "- Openai에서는 내부에서 자동으로 캐싱 routing이 되고 커스텀이 불가하지만, anthropic에서는 message 단위로 cache 설정할 수 있어서 캐시 관련 커스텀 제어가 가능하다.\n",
    "- response.content.ciataion 통해 어떤 내용에서 인용했는지 알 수 있어서, RAG 이용할 때 검증할 때 유용할 것 같다.\n",
    "- 내부에서 PDF 전처리된 페이지 이미지, 텍스트가 어떻게 모델에 입력되는지 자세히 모르기 때문에 작업 검증은 필요하다.\n",
    "    - 기존 모델 param을 그대로 입력하는 것으로 보아, PDF 입력을 위해 fine-tuning된 모델을 사용하는 것은 아니며\n",
    "    - `\"type\": \"document\"` 명시함으로써, 그냥 전처리 코드만 작동되지 않을까 싶다.\n",
    "    - 페이지 사이에 걸쳐있는 문장의 경우도 있는데, 텍스트가 페이지 이미지 별로 파싱해서 들어간다면, 불완전한 문장이 존재할 것이고, 페이지 텍스트들이 모두 merge되어 들어간다면, 완전한 문장이 입력될 듯하다.\n",
    "    - DocumentBlockParam content 스펙을 확인해보면, `context`, `title` 옵션을 넣을 수 있는데, 아마 추출된 텍스트는 `context`에 들어가고, 추출된 이미지는 image input으로 들어갈 듯하다.\n",
    "- Document mode는 아직 OpenAI SDK에서는 사용할 수 없는 듯하다. [참고](https://platform.claude.com/docs/en/api/openai-sdk#messages-array-fields)\n",
    "- PDF Support를 이용하여 markdown으로 변환할 때, 이미지 content에 대한 내용을 output하지 않기 때문에 아쉬움은 있다. tool로 이미지 생성 API를 사용할 수 있게 하면 될 듯하지만, 가격이 좀 나올 수 있겠다.\n",
    "- Openai에서도 File input 통한 'PDF content understanding'을 지원한다. 역시 비슷하게 텍스트와 페이지 이미지를 추출하여 모델에 입력되는 원리다. [참고](https://platform.openai.com/docs/guides/pdf-files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c97c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
