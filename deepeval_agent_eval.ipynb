{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c993bb",
   "metadata": {},
   "source": [
    "ref: https://deepeval.com/guides/guides-ai-agent-evaluation\n",
    "- ì˜¤í”ˆ ì†ŒìŠ¤ LLM í‰ê°€ í”„ë ˆì„ì›Œí¬\n",
    "- Pytestì²˜ëŸ¼ LLM ì¶œë ¥ì— ëŒ€í•´ ì†ì‰½ê²Œ ìœ ë‹› í…ŒìŠ¤íŠ¸ë¥¼ ì‘ì„±í•  ìˆ˜ ìˆìŒ\n",
    "- ì—°êµ¬ì ìœ¼ë¡œ ë’·ë°›ì¹¨ëœ ê²ƒì„ í¬í•¨í•´, 30ê°œ ì´ìƒì˜ LLM ê¸°ë°˜ í‰ê°€ ì§€í‘œë¥¼ ë°”ë¡œ ê°€ì ¸ë‹¤ ì“¸ ìˆ˜ ìˆìŒ\n",
    "- E2E(end-to-end)ì™€ ì»´í¬ë„ŒíŠ¸ ë ˆë²¨ í‰ê°€ë¥¼ ëª¨ë‘ ì§€ì›\n",
    "- RAG, ì—ì´ì „íŠ¸, ì±—ë´‡ ë“± ì‚¬ì‹¤ìƒ ëŒ€ë¶€ë¶„ì˜ LLM í™œìš© ì‚¬ë¡€ì— ëŒ€í•œ í‰ê°€ ì§€ì›\n",
    "- ìµœì‹  evolution ê¸°ë²•ì„ í™œìš©í•œ í•©ì„±(synthetic) ë°ì´í„°ì…‹ ìƒì„± ê¸°ëŠ¥\n",
    "- ì§€í‘œ(metric)ë¥¼ ê°„ë‹¨íˆ ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆí•  ìˆ˜ ìˆê³ , ë‹¤ì–‘í•œ í™œìš© ì¼€ì´ìŠ¤ë¥¼ í¬ê´„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8924f105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0dbf58",
   "metadata": {},
   "source": [
    "`@observe` ë°ì½”ë ˆì´í„°ë¥¼ ì´ìš©í•˜ì—¬ trace ê°€ëŠ¥í•˜ë‹¤.\n",
    "\n",
    "ìë™ì ìœ¼ë¡œ trace ëŒ€ìƒ ì½”ë“œë¥¼ ì°¾ëŠ”ë‹¤ê³ í•œë‹¤.\n",
    "\n",
    "Confident AI í†µí•´ì„œ ëª¨ë‹ˆí„°ë§ í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21863a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from deepeval.tracing import observe\n",
    "from deepeval.dataset import Golden, EvaluationDataset\n",
    "\n",
    "client = OpenAI()\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_flights\",\n",
    "            \"description\": \"Search for available flights between two cities\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"origin\": {\"type\": \"string\"},\n",
    "                    \"destination\": {\"type\": \"string\"},\n",
    "                    \"date\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"origin\", \"destination\", \"date\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"book_flight\",\n",
    "            \"description\": \"Book a specific flight by ID\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"flight_id\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"flight_id\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "@observe(type=\"tool\")\n",
    "def search_flights(origin, destination, date):\n",
    "    # Simulated flight search\n",
    "    return [{\"id\": \"FL123\", \"price\": 450}, {\"id\": \"FL456\", \"price\": 380}]\n",
    "\n",
    "@observe(type=\"tool\")\n",
    "def book_flight(flight_id):\n",
    "    # Simulated booking\n",
    "    return {\"confirmation\": \"CONF-789\", \"flight_id\": flight_id}\n",
    "\n",
    "@observe(type=\"llm\")\n",
    "def call_openai(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        tools=tools\n",
    "    )\n",
    "    return response\n",
    "\n",
    "@observe(type=\"agent\")\n",
    "def travel_agent(user_input):\n",
    "    messages = [{\"role\": \"user\", \"content\": user_input}]\n",
    "\n",
    "    # LLM reasons about which tool to call\n",
    "    response = call_openai(messages)\n",
    "    tool_call = response.choices[0].message.tool_calls[0]\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    # Execute the tool\n",
    "    flights = search_flights(args[\"origin\"], args[\"destination\"], args[\"date\"])\n",
    "\n",
    "    # LLM decides to book the cheapest\n",
    "    cheapest = min(flights, key=lambda x: x[\"price\"])\n",
    "    messages.append({\"role\": \"assistant\", \"content\": f\"Found flights. Booking cheapest: {cheapest['id']}\"})\n",
    "\n",
    "    booking = book_flight(cheapest[\"id\"])\n",
    "\n",
    "    return f\"Booked flight {cheapest['id']} for ${cheapest['price']}. Confirmation: {booking['confirmation']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9992aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.metrics import PlanQualityMetric, PlanAdherenceMetric\n",
    "\n",
    "plan_quality = PlanQualityMetric()\n",
    "plan_adherence = PlanAdherenceMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5af54556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a73d97a7814251a06cfc6a0f3c4f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - âœ… Plan Quality (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: There are no plans to evaluate within the trace of your agent's execution. Please check if the agent's planning or reasoning or thinking is stored in the trace attributes., error: None)\n",
      "  - âœ… Plan Adherence (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: There were no plans to evaluate within the trace of your agent's execution. Please check if the agent's planning or reasoning or thinking is stored in any one of the trace attributes., error: None)\n",
      "  - âœ… Plan Quality (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: There are no plans to evaluate within the trace of your agent's execution. Please check if the agent's planning or reasoning or thinking is stored in the trace attributes., error: None)\n",
      "  - âœ… Plan Adherence (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: There were no plans to evaluate within the trace of your agent's execution. Please check if the agent's planning or reasoning or thinking is stored in any one of the trace attributes., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Book a flight from NYC to London for next Monday\n",
      "  - actual output: Booked flight FL456 for $380. Confirmation: CONF-789\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - âœ… Plan Quality (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: There are no plans to evaluate within the trace of your agent's execution. Please check if the agent's planning or reasoning or thinking is stored in the trace attributes., error: None)\n",
      "  - âœ… Plan Adherence (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: There were no plans to evaluate within the trace of your agent's execution. Please check if the agent's planning or reasoning or thinking is stored in any one of the trace attributes., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: {'user_input': 'Book a flight from NYC to London for next Monday'}\n",
      "  - actual output: Booked flight FL456 for $380. Confirmation: CONF-789\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Plan Quality: 100.00% pass rate\n",
      "Plan Adherence: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">âš  WARNING:</span> No hyperparameters logged.\n",
       "Â» <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33mâš  WARNING:\u001b[0m No hyperparameters logged.\n",
       "Â» \u001b]8;id=588779;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Evaluation completed ğŸ‰! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.</span>08s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.026632000000000003</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "Â» Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   Â» Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "Â» Want to share evals with your team, or a place for your test cases to live? â¤ï¸ ğŸ¡\n",
       "  Â» Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141mâœ“\u001b[0m Evaluation completed ğŸ‰! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m4.\u001b[0m08s | token cost: \u001b[1;36m0.026632000000000003\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "Â» Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   Â» Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "Â» Want to share evals with your team, or a place for your test cases to live? â¤ï¸ ğŸ¡\n",
       "  Â» Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepeval.dataset import EvaluationDataset, Golden\n",
    "\n",
    "# Create dataset\n",
    "dataset = EvaluationDataset(goldens=[\n",
    "    Golden(input=\"Book a flight from NYC to London for next Monday\")\n",
    "])\n",
    "\n",
    "# Loop through dataset with metrics\n",
    "for golden in dataset.evals_iterator(metrics=[plan_quality, plan_adherence]):\n",
    "    travel_agent(golden.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94ea6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
