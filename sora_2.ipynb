{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf56f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "class Sora2:\n",
    "    def __init__(self):\n",
    "        self.openai = OpenAI()\n",
    "\n",
    "    def generate_video(self, prompt: str, file_name: str, seconds=\"12\", size=\"720x1280\", model=\"sora-2\"):\n",
    "        if \".mp4\" not in file_name:\n",
    "            file_name = file_name + \".mp4\"\n",
    "\n",
    "        video = self.openai.videos.create(\n",
    "            model=model,\n",
    "            prompt=prompt,\n",
    "            # input_reference=None,\n",
    "            seconds=seconds,\n",
    "            size=size\n",
    "        )\n",
    "\n",
    "        print(\"Video generation started:\\n\", video)\n",
    "\n",
    "        progress = getattr(video, \"progress\", 0)\n",
    "        bar_length = 30\n",
    "\n",
    "        while video.status in (\"in_progress\", \"queued\"):\n",
    "            # Refresh status\n",
    "            video = self.openai.videos.retrieve(video.id)\n",
    "            progress = getattr(video, \"progress\", 0)\n",
    "\n",
    "            filled_length = int((progress / 100) * bar_length)\n",
    "            bar = \"=\" * filled_length + \"-\" * (bar_length - filled_length)\n",
    "            status_text = \"Queued\" if video.status == \"queued\" else \"Processing\"\n",
    "\n",
    "            print(f\"{status_text}: [{bar}] {progress:.1f}%\", end=\"\\r\", flush=True)\n",
    "            time.sleep(1)\n",
    "\n",
    "        # Move to next line after progress loop\n",
    "        print(\"\\n\")\n",
    "\n",
    "        if video.status == \"failed\":\n",
    "            message = getattr(\n",
    "                getattr(video, \"error\", None), \"message\", \"Video generation failed\"\n",
    "            )\n",
    "            print(message)\n",
    "        else:\n",
    "            print(\"Video generation completed:\", video)\n",
    "            print(\"Downloading video content...\")\n",
    "\n",
    "            content = self.openai.videos.download_content(video.id, variant=\"video\")\n",
    "            content.write_to_file(file_name)\n",
    "\n",
    "            print(f\"Wrote {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af5ee16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video generation started:\n",
      " Video(id='video_68f4c510426481938a8783a8d33c07a30d53eb2df05c18bd', completed_at=None, created_at=1760871696, error=None, expires_at=None, model='sora-2-pro', object='video', progress=0, remixed_from_video_id=None, seconds='12', size='1024x1792', status='queued')\n",
      "Processing: [==============================] 100.0%\n",
      "\n",
      "Video generation completed: Video(id='video_68f4c510426481938a8783a8d33c07a30d53eb2df05c18bd', completed_at=1760872524, created_at=1760871696, error=None, expires_at=1760876124, model='sora-2-pro', object='video', progress=100, remixed_from_video_id=None, seconds='12', size='1024x1792', status='completed')\n",
      "Downloading video content...\n",
      "Wrote video.mp4\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class SoraModel(Enum):\n",
    "    SORA_2 = \"sora-2\"\n",
    "    SORA_2_PRO = \"sora-2-pro\"\n",
    "\n",
    "class SoraVideoSize(Enum):\n",
    "    SORA_2_720x1280 = \"720x1280\"\n",
    "    SORA_2_1280x720 = \"1280x720\"\n",
    "    SORA_2_PRO_720x1280 = \"720x1280\"\n",
    "    SORA_2_PRO_1280x720 = \"1280x720\"\n",
    "    SORA_2_PRO_1024x1792 = \"1024x1792\"\n",
    "    SORA_2_PRO_1792x1024 = \"1792x1024\"\n",
    "\n",
    "class SoraVideoDuration(Enum):\n",
    "    SECONDS_4 = \"4\"\n",
    "    SECONDS_8 = \"8\"\n",
    "    SECONDS_12 = \"12\"\n",
    "\n",
    "\n",
    "class SoraDownloadVariant(Enum):\n",
    "    VIDEO = \"video\"\n",
    "    THUMBNAIL = \"thumbnail\"\n",
    "    SPRITESHEET = \"spritesheet\"\n",
    "\n",
    "\n",
    "PROMPT = \"\"\"\n",
    "Format & Look\n",
    "Duration 4s; 180° shutter; digital capture emulating 65 mm photochemical contrast; fine grain; subtle halation on speculars; no gate weave.\n",
    "\n",
    "Lenses & Filtration\n",
    "32 mm / 50 mm spherical primes; Black Pro-Mist 1/4; slight CPL rotation to manage glass reflections on train windows.\n",
    "\n",
    "Grade / Palette\n",
    "Highlights: clean morning sunlight with amber lift.\n",
    "Mids: balanced neutrals with slight teal cast in shadows.\n",
    "Blacks: soft, neutral with mild lift for haze retention.\n",
    "\n",
    "Lighting & Atmosphere\n",
    "Natural sunlight from camera left, low angle (07:30 AM).\n",
    "Bounce: 4x4 ultrabounce silver from trackside.\n",
    "Negative fill from opposite wall.\n",
    "Practical: sodium platform lights on dim fade.\n",
    "Atmos: gentle mist; train exhaust drift through light beam.\n",
    "\n",
    "Location & Framing\n",
    "Seoul urban commuter platform, dawn.\n",
    "Foreground: yellow safety line, a bottle of whiskey on bench.\n",
    "Midground: waiting passengers silhouetted in haze.\n",
    "Background: arriving train braking to a stop.\n",
    "Avoid signage or corporate branding.\n",
    "\n",
    "Wardrobe / Props / Extras\n",
    "Main subject: mid-30s korean street male dancer, black baseball cap, navy hoodie, backpack with some key-rings, holding phone loosely at side.\n",
    "Extras: commuters in muted tones; one cyclist pushing bike.\n",
    "Props: paper coffee cup, rolling luggage, LED departure board (generic destinations).\n",
    "\n",
    "Sound\n",
    "Diegetic only: faint rail screech, train brakes hiss, distant announcement muffled (-20 LUFS), low ambient hum.\n",
    "Footsteps and paper rustle; no score or added foley.\n",
    "\n",
    "Optimized Shot List (2 shots / 4 s total)\n",
    "\n",
    "0.00-2.40 — “Arrival Drift” (32 mm, shoulder-mounted slow dolly left)\n",
    "Camera slides past platform signage edge; shallow focus reveals dancer mid-frame looking down tracks. Morning light blooms across lens; train headlights flare softly through mist. Purpose: establish setting and tone, hint anticipation.\n",
    "\n",
    "2.40-4.00 — “Turn and Pause” (50 mm, slow arc in)\n",
    "Cut to tighter over-shoulder arc as train halts; dancer turns slightly toward camera, catching sunlight rim across cheek and phone screen reflection. Eyes flick up toward something unseen. Purpose: create human focal moment with minimal motion.\n",
    "\n",
    "Camera Notes (Why It Reads)\n",
    "Keep eyeline low and close to lens axis for intimacy.\n",
    "Allow micro flares from train glass as aesthetic texture.\n",
    "Preserve subtle handheld imperfection for realism.\n",
    "Do not break silhouette clarity with overexposed flare; retain skin highlight roll-off.\n",
    "\n",
    "Finishing\n",
    "Fine-grain overlay with mild chroma noise for realism; restrained halation on practicals; warm-cool LUT for morning split tone.\n",
    "Mix: prioritize train and ambient detail over footstep transients.\n",
    "Poster frame: traveler mid-turn, golden rim light, arriving train soft-focus in background haze.\n",
    "\"\"\"\n",
    "\n",
    "sora = Sora2()\n",
    "sora.generate_video(\n",
    "    prompt=PROMPT,\n",
    "    file_name=\"sora_2_video.mp4\",\n",
    "    seconds=\"12\",\n",
    "    size=\"1024x1792\",\n",
    "    model=\"sora-2-pro\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64550c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = 'video_68f4c510426481938a8783a8d33c07a30d53eb2df05c18bd'\n",
    "content = sora.openai.videos.download_content(video_id, variant=\"spritesheet\")\n",
    "content.write_to_file(\"spritesheet.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e2d22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
